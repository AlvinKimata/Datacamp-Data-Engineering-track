## Using curl documentation.

Run 
```bash
man curl
``` 
to obtain `curl's` documentation.

### Downloading single file using curl.

Use curl to download the file from the redirected URL.
```bash
curl -L https://assets.datacamp.com/production/repositories/4180/datasets/eb1d6a36fa3039e4e00064797e1a1600d267b135/201812SpotifyData.zip
```
Download and rename the file in the same step.
```bash
curl -o Spotify201812.zip -L https://assets.datacamp.com/production/repositories/4180/datasets/eb1d6a36fa3039e4e00064797e1a1600d267b135/201812SpotifyData.zip
```

### Downloading multiple files using curl.
To minimize having to type the long URLs over and over again, we'd like to download all of these files using a single curl command.

``` bash
curl -O https://s3.amazonaws.com/assets.datacamp.com/production/repositories/4180/datasets/files/datafile[001-100].txt
```

Print all downloaded files to directory.
```bash
ls datafile*.txt
```

## Downloading data using `wget`.

Used to download data from HTTP(S) and FTP.
It is better than curl at downloading multiple files recursively.

Option flages unique to `wget` are:
- `-b`: Go to background immediately after startup.
- `-q`: Turn off the `wget` output.
- `-c`: Resume broken download (continue getting a partially-downloaded file)

```bash
wget -bqc https://websitename.com/datafilename.txt
```

### Advanced downloading using Wget.
Downloading files from URL locations stored in a text file.

```bash
wget -i url_list.txt
```
Setting an upper download bandwidth limit (by default bytes per second)

```bash
wget --limit-rate=200k -i url_list.txt
```

Setting download constraints for small files.
Set a mandatory pause time (in seconds between file downloads with `--wait`.

```bash
wget --wait=2.5 -i url_list.txt
```